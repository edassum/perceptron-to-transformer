# perceptron-to-transformer
# Perceptron to Transformer

This repository documents my deep learning learning journey — starting from the Perceptron and gradually progressing toward modern Transformer architectures.

The goal is to deeply understand how neural networks work internally rather than relying only on high-level frameworks.

## Topics Covered
- Perceptron
- Linear Models
- Gradient Descent
- Backpropagation
- Neural Networks
- Activation Functions
- CNNs
- RNNs
- Attention Mechanism
- Transformers
- LLM Fundamentals

## Philosophy
Learn → Implement → Experiment → Understand.

All implementations aim to be simple, educational, and built from first principles.
